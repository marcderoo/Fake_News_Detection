{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_isot_dataset(fake_file, true_file):\n",
    "    \"\"\"Charge les fichiers de données et retourne un forFrame pour les données de fausses et vraies nouvelles.\"\"\"\n",
    "    fake_data = pd.read_csv(fake_file)\n",
    "    true_data = pd.read_csv(true_file)\n",
    "    \n",
    "    fake_data['label'] = 0  # Label 0 pour les fausses nouvelles\n",
    "    true_data['label'] = 1  # Label 1 pour les vraies nouvelles\n",
    "    \n",
    "    return pd.concat([fake_data, true_data], ignore_index=True)\n",
    "\n",
    "# Exemple de chargement de données\n",
    "train_isot = load_isot_dataset(\"data/Fake.csv\", \"data/True.csv\")\n",
    "\n",
    "# Diviser les données en caractéristiques (X) et labels (y)\n",
    "X_isot = train_isot[\"text\"]  # Le texte des articles\n",
    "y_isot = train_isot[\"label\"]  # Les labels (0 ou 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for = pd.read_csv(\"data/fake_or_real_news.csv\")\n",
    "\n",
    "# Remplacer \"FAKE\" par 0 et \"REAL\" par 1 dans la colonne \"label\"\n",
    "train_for['label'] = train_for['label'].map({'FAKE': 0, 'REAL': 1})\n",
    "\n",
    "# Diviser les données en caractéristiques (X) et labels (y)\n",
    "X_for = train_for[\"text\"]  # Le texte des articles\n",
    "y_for = train_for[\"label\"]  # Les labels (0 ou 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_full(text):\n",
    "    \"\"\"Prétraitement complet pour les modèles Bag of Words et TF-IDF (avec lemmatisation).\"\"\"\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Suppression des URLs et handles Twitter\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\S+\", \"\", text)\n",
    "    \n",
    "    # Suppression de la ponctuation et des espaces supplémentaires\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # Suppression des espaces blancs supplémentaires\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bow_features(X_train, X_test):\n",
    "    \"\"\"Extrait les caractéristiques Bag of Words des jeux de données après prétraitement complet.\"\"\"\n",
    "    \n",
    "    # Appliquer le prétraitement complet sur les textes\n",
    "    X_train_cleaned = [preprocess_full(text) for text in X_train]\n",
    "    X_test_cleaned = [preprocess_full(text) for text in X_test]\n",
    "    \n",
    "    # Initialisation du CountVectorizer\n",
    "    vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "    \n",
    "    # Transformation des données en matrices BoW\n",
    "    X_train_bow = vectorizer.fit_transform(X_train_cleaned)\n",
    "    X_test_bow = vectorizer.transform(X_test_cleaned)\n",
    "    \n",
    "    return X_train_bow, X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tfidf_features(X_train, X_test):\n",
    "    \"\"\"Extrait les caractéristiques TF-IDF des jeux de données après prétraitement complet.\"\"\"\n",
    "    \n",
    "    # Appliquer le prétraitement complet sur les textes\n",
    "    X_train_cleaned = [preprocess_full(text) for text in X_train]\n",
    "    X_test_cleaned = [preprocess_full(text) for text in X_test]\n",
    "    \n",
    "    # Initialisation du TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    \n",
    "    # Transformation des données en matrices TF-IDF\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train_cleaned)\n",
    "    X_test_tfidf = vectorizer.transform(X_test_cleaned)\n",
    "    \n",
    "    return X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W2V & BERT & LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_light(text):\n",
    "    \"\"\"Prétraitement léger pour les modèles Word2Vec, BERT et Linguistic Cues (sans lemmatisation).\"\"\"\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Suppression des URLs et handles Twitter\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\S+\", \"\", text)\n",
    "    \n",
    "    # Suppression des espaces blancs supplémentaires\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec loaded! Vocab size: 3000000\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "# Charger le modèle Word2Vec (évite de le télécharger à chaque exécution)\n",
    "try:\n",
    "    word2vec_model = KeyedVectors.load(\"word2vec-google-news-300.kv\")  # Si déjà téléchargé\n",
    "except FileNotFoundError:\n",
    "    word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "    word2vec_model.save(\"word2vec-google-news-300.kv\")  # Sauvegarde pour éviter le re-téléchargement\n",
    "\n",
    "print(f\"Word2Vec loaded! Vocab size: {len(word2vec_model.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word2vec_features(X_train, X_test):\n",
    "    \"\"\"Extrait les caractéristiques Word2Vec des jeux de données après prétraitement léger.\"\"\"\n",
    "    \n",
    "    def text_to_vec(text):\n",
    "        \"\"\"Convertit un texte en un vecteur moyen des embeddings de ses mots.\"\"\"\n",
    "        words = text.split()\n",
    "        vecs = np.array([word2vec_model[word] for word in words if word in word2vec_model])\n",
    "        return np.mean(vecs, axis=0) if len(vecs) > 0 else np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    # Appliquer le prétraitement léger et vectoriser en une seule ligne\n",
    "    X_train_cleaned = [preprocess_light(text) for text in X_train]\n",
    "    X_test_cleaned = [preprocess_light(text) for text in X_test]\n",
    "    \n",
    "    X_train_word2vec = np.array([text_to_vec(text) for text in X_train_cleaned])\n",
    "    X_test_word2vec = np.array([text_to_vec(text) for text in X_test_cleaned])\n",
    "    \n",
    "    return X_train_word2vec, X_test_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bert_features(X_train, X_test, batch_size=32):\n",
    "    \"\"\"Extrait les caractéristiques BERT en batch pour améliorer la vitesse.\"\"\"\n",
    "    \n",
    "    def text_to_bert_vec(texts):\n",
    "        \"\"\"Convertir une liste de textes en vecteurs BERT (par batch).\"\"\"\n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "    # Appliquer le prétraitement léger et transformer en batchs\n",
    "    X_train_cleaned = [preprocess_light(text) for text in X_train]\n",
    "    X_test_cleaned = [preprocess_light(text) for text in X_test]\n",
    "\n",
    "    # Traiter en batchs pour accélérer\n",
    "    X_train_bert = np.vstack([text_to_bert_vec(X_train_cleaned[i:i+batch_size]) for i in range(0, len(X_train_cleaned), batch_size)])\n",
    "    X_test_bert = np.vstack([text_to_bert_vec(X_test_cleaned[i:i+batch_size]) for i in range(0, len(X_test_cleaned), batch_size)])\n",
    "    \n",
    "    return X_train_bert, X_test_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linguistic_cues(X_train, X_test):\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import spacy\n",
    "\n",
    "    # Charger le modèle spaCy anglais\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def count_words(doc):\n",
    "        return len([token for token in doc if token.is_alpha])\n",
    "\n",
    "    def count_syllables(text):\n",
    "        vowels = \"aeiouyAEIOUY\"\n",
    "        return sum([sum(1 for char in word if char in vowels) for word in text.split()])\n",
    "\n",
    "    def count_sentences(doc):\n",
    "        return len(list(doc.sents))\n",
    "\n",
    "    def count_long_words(doc, threshold=6):\n",
    "        return sum(1 for token in doc if len(token.text) > threshold and token.is_alpha)\n",
    "\n",
    "    def count_all_caps(doc):\n",
    "        return sum(1 for token in doc if token.text.isupper())\n",
    "\n",
    "    def count_unique_words(doc):\n",
    "        return len(set(token.text.lower() for token in doc if token.is_alpha))\n",
    "\n",
    "    def count_personal_pronouns(doc):\n",
    "        pronouns = {'i', 'we', 'she', 'he', 'him', 'me', 'us'}\n",
    "        return sum(1 for token in doc if token.text.lower() in pronouns)\n",
    "\n",
    "    def count_articles(doc):\n",
    "        articles = {'a', 'an', 'the'}\n",
    "        return sum(1 for token in doc if token.text.lower() in articles)\n",
    "\n",
    "    def count_pos_tags(doc, pos_tags):\n",
    "        return sum(1 for token in doc if token.tag_ in pos_tags)\n",
    "\n",
    "    def count_punctuation(text, p):\n",
    "        return text.count(p)\n",
    "\n",
    "    def compute_features(texts):\n",
    "        features = []\n",
    "        docs = list(nlp.pipe(texts))\n",
    "        for doc, text in zip(docs, texts):\n",
    "            wc = count_words(doc)\n",
    "            sc = count_sentences(doc)\n",
    "            data = {\n",
    "                'word_count': wc,\n",
    "                'syllables_count': count_syllables(text),\n",
    "                'sentence_count': sc,\n",
    "                'words_per_sentence': wc / max(sc, 1),\n",
    "                'long_words_count': count_long_words(doc),\n",
    "                'all_caps_count': count_all_caps(doc),\n",
    "                'unique_words_count': count_unique_words(doc),\n",
    "                'personal_pronouns%': count_personal_pronouns(doc) / max(wc, 1),\n",
    "                'articles%': count_articles(doc) / max(wc, 1),\n",
    "                'prepositions%': count_pos_tags(doc, {'IN'}) / max(wc, 1),\n",
    "                'auxiliary_verbs%': count_pos_tags(doc, {'VB', 'VBP', 'VBG'}) / max(wc, 1),\n",
    "                'common_adverbs%': count_pos_tags(doc, {'RB', 'RBR', 'RBS'}) / max(wc, 1),\n",
    "                'conjunctions%': count_pos_tags(doc, {'CC'}) / max(wc, 1),\n",
    "                'negations%': count_pos_tags(doc, {'RB'}) / max(wc, 1),\n",
    "                'common_verbs%': count_pos_tags(doc, {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}) / max(wc, 1),\n",
    "                'common_adjectives%': count_pos_tags(doc, {'JJ', 'JJR', 'JJS'}) / max(wc, 1),\n",
    "                'punctuation_count': sum(count_punctuation(text, p) for p in ['.', ',', ':', ';', '!', '?', '-', '(', ')']),\n",
    "                'full_stop_count': count_punctuation(text, '.'),\n",
    "                'commas_count': count_punctuation(text, ','),\n",
    "                'colons_count': count_punctuation(text, ':'),\n",
    "                'semi_colons_count': count_punctuation(text, ';'),\n",
    "                'question_marks_count': count_punctuation(text, '?'),\n",
    "                'exclamation_marks_count': count_punctuation(text, '!'),\n",
    "                'dashes_count': count_punctuation(text, '-'),\n",
    "                'apostrophe_count': count_punctuation(text, \"'\"),\n",
    "                'brackets_count': count_punctuation(text, '(') + count_punctuation(text, ')')\n",
    "            }\n",
    "            features.append(data)\n",
    "        return pd.DataFrame(features)\n",
    "\n",
    "    return compute_features(X_train), compute_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, X_test) = (X_isot, X_for)\n",
    "# X_isot_BoW, _ = extract_bow_features(X_isot, X_for)\n",
    "# X_isot_tfidf, _ = extract_tfidf_features(X_isot, X_for)\n",
    "\n",
    "# X_for_BoW, _ = extract_bow_features(X_for, X_isot)\n",
    "# X_for_tfidf, _ = extract_tfidf_features(X_for, X_isot)\n",
    "\n",
    "# X_isot_W2V, _ = extract_word2vec_features(X_isot, X_for)\n",
    "# X_for_W2V, _ = extract_word2vec_features(X_for, X_isot)\n",
    "\n",
    "X_isot_LC, _ = extract_linguistic_cues(X_isot, X_for)\n",
    "X_for_LC, _ = extract_linguistic_cues(X_for, X_isot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Sauvegarde des features dans des fichiers\n",
    "# with open(\"X_isot_LC.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(X_isot_LC, f)\n",
    "\n",
    "# with open(\"X_for_LC.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(X_for_LC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, y_train, X_test, y_test, model_type=\"svm\"):\n",
    "    \"\"\"Entraîne un modèle sur 100% des données d'entraînement et évalue sur 100% des données de test.\"\"\"\n",
    "    # Initialisation du modèle en fonction du type\n",
    "    if model_type == \"svm\":\n",
    "        model = SVC(kernel=\"linear\")\n",
    "    elif model_type == \"random_forest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model_type == \"logistic_regression\":\n",
    "        model = LogisticRegression()\n",
    "    elif model_type == \"gradient_boosting\":\n",
    "        model = GradientBoostingClassifier()\n",
    "    elif model_type == \"adaboost\":\n",
    "        model = AdaBoostClassifier()\n",
    "    elif model_type == \"neural_network\":\n",
    "        model = MLPClassifier()\n",
    "\n",
    "    # Entraîner le modèle sur toutes les données d'entraînement\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Faire des prédictions sur les données de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculer l'accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy du modèle {model_type} : {accuracy}\")\n",
    "\n",
    "    # Création du dossier pour sauvegarder les modèles\n",
    "    os.makedirs(\"cross_models_LC\", exist_ok=True)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    model_filename = f\"cross_models_LC/{model_type}_isot_LC.pkl\"\n",
    "    with open(model_filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle svm : 0.6553744042050871\n"
     ]
    }
   ],
   "source": [
    "# BOW\n",
    "\n",
    "# Entraînement sur ISOT et évaluation sur FakeOrReal\n",
    "# model_isot, accuracy_isot_to_for = train_and_evaluate(X_isot_BoW, y_isot, X_for_BoW, y_for, model_type=\"svm\")\n",
    "# Entraînement sur FakeOrReal et évaluation sur ISOT\n",
    "# model_for, accuracy_for_to_isot = train_and_evaluate(X_for_BoW, y_for, X_isot_BoW, y_isot, model_type=\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle svm : 0.5327186066194485\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "# Entraînement sur ISOT et évaluation sur FakeOrReal\n",
    "# model_isot, accuracy_isot_to_for = train_and_evaluate(X_isot_tfidf, y_isot, X_for_tfidf, y_for, model_type=\"svm\")\n",
    "# Entraînement sur FakeOrReal et évaluation sur ISOT\n",
    "# model_for, accuracy_for_to_isot = train_and_evaluate(X_for_tfidf, y_for, X_isot_tfidf, y_isot, model_type=\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle svm : 0.7117911710989354\n"
     ]
    }
   ],
   "source": [
    "# W2V\n",
    "\n",
    "# Entraînement sur ISOT et évaluation sur FakeOrReal\n",
    "# model_isot, accuracy_isot_to_for = train_and_evaluate(X_isot_W2V, y_isot, X_for_W2V, y_for, model_type=\"svm\")\n",
    "# Entraînement sur FakeOrReal et évaluation sur ISOT\n",
    "# model_for, accuracy_for_to_isot = train_and_evaluate(X_for_W2V, y_for, X_isot_W2V, y_isot, model_type=\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X_isot_LC.pkl\", \"rb\") as f:\n",
    "    X_isot_LC = pickle.load(f)\n",
    "\n",
    "with open(\"X_for_LC.pkl\", \"rb\") as f:\n",
    "    X_for_LC = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle svm : 0.619403982360016\n"
     ]
    }
   ],
   "source": [
    "# LC\n",
    "\n",
    "# Entraînement sur ISOT et évaluation sur FakeOrReal\n",
    "model_isot, accuracy_isot_to_for = train_and_evaluate(X_isot_LC, y_isot, X_for_LC, y_for, model_type=\"svm\")\n",
    "# Entraînement sur FakeOrReal et évaluation sur ISOT\n",
    "# model_for, accuracy_for_to_isot = train_and_evaluate(X_for_LC, y_for, X_isot_LC, y_isot, model_type=\"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et évaluer le modèle\n",
    "def evaluate_model(X_test, y_test, model_path):\n",
    "    \"\"\"Évalue un modèle chargé depuis un fichier.\"\"\"\n",
    "    try:\n",
    "        # Charger le modèle depuis le fichier pickle\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur : fichier {model_path} introuvable.\")\n",
    "        return\n",
    "\n",
    "    # Prédiction avec le modèle chargé\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Afficher les résultats d'évaluation\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5120757695343331\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65      3164\n",
      "           1       0.55      0.13      0.21      3171\n",
      "\n",
      "    accuracy                           0.51      6335\n",
      "   macro avg       0.53      0.51      0.43      6335\n",
      "weighted avg       0.53      0.51      0.43      6335\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2839  325]\n",
      " [2766  405]]\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "\n",
    "# Entraînement sur ISOT et évaluation sur FakeOrReal\n",
    "evaluate_model(X_for_BoW, y_for, \"cross_models_BoW/svm_isot_BoW.pkl\")\n",
    "# Entraînement sur FakeOrReal et évaluation sur ISOT\n",
    "# evaluate_model(X_isot_BoW, y_isot, \"cross_models_BoW/svm_for_BoW.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "\n",
    "# Entraînement sur ISOT et évaluation sur FakeOrReal\n",
    "evaluate_model(X_for_tfidf, y_for, \"cross_models_tfidf/svm_isot_tfidf.pkl\")\n",
    "# Entraînement sur FakeOrReal et évaluation sur ISOT\n",
    "evaluate_model(X_isot_BoW, y_isot, \"cross_models_tfidf/svm_for_tfidf.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
